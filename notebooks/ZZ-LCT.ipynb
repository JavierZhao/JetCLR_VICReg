{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6b7818a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-21T23:49:06.559197Z",
     "start_time": "2023-08-21T23:49:05.632575Z"
    }
   },
   "outputs": [],
   "source": [
    "# Perform the Linear Classifier Test (LCT) on the representations learned by VICReg.\n",
    "\n",
    "# load standard python modules\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "import copy\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time\n",
    "import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "# load torch modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bea71c1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-21T23:49:07.419469Z",
     "start_time": "2023-08-21T23:49:06.561298Z"
    }
   },
   "outputs": [],
   "source": [
    "# load custom modules required for jetCLR training\n",
    "from src.models.jet_augs import (\n",
    "    rotate_jets,\n",
    "    distort_jets,\n",
    "    rescale_pts,\n",
    "    crop_jets,\n",
    "    translate_jets,\n",
    "    collinear_fill_jets,\n",
    ")\n",
    "from src.models.transformer import Transformer\n",
    "from src.features.perf_eval import get_perf_stats, linear_classifier_test\n",
    "from src.models.pretrain_vicreg import VICReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "838320f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-21T23:49:07.658026Z",
     "start_time": "2023-08-21T23:49:07.421263Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ssl-jet-vol-v2/JetCLR_VICReg/notebooks\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e87678f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-21T23:49:07.664602Z",
     "start_time": "2023-08-21T23:49:07.659892Z"
    }
   },
   "outputs": [],
   "source": [
    "project_dir = \"/ssl-jet-vol-v2/JetCLR_VICReg\"\n",
    "\n",
    "# load the data files and the label files from the specified directory\n",
    "def load_data(dataset_path, flag, n_files=-1):\n",
    "    data_files = glob.glob(f\"{dataset_path}/{flag}/processed/3_features/*\")\n",
    "\n",
    "    data = []\n",
    "    for i, file in enumerate(data_files):\n",
    "        data += torch.load(f\"{dataset_path}/{flag}/processed/3_features/data_{i}.pt\")\n",
    "        print(f\"--- loaded data file {i} from `{flag}` directory\")\n",
    "        if n_files != -1 and i == n_files - 1:\n",
    "            break\n",
    "\n",
    "    return data\n",
    "\n",
    "def load_labels(dataset_path, flag, n_files=-1):\n",
    "    data_files = glob.glob(f\"{dataset_path}/{flag}/processed/3_features/*\")\n",
    "\n",
    "    data = []\n",
    "    for i, file in enumerate(data_files):\n",
    "        data += torch.load(f\"{dataset_path}/{flag}/processed/3_features/labels_{i}.pt\")\n",
    "        print(f\"--- loaded label file {i} from `{flag}` directory\")\n",
    "        if n_files != -1 and i == n_files - 1:\n",
    "            break\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63ed5f08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-21T23:49:07.671659Z",
     "start_time": "2023-08-21T23:49:07.666863Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_backbones(args):\n",
    "    x_backbone = Transformer(input_dim=args.x_inputs)\n",
    "    y_backbone = x_backbone if args.shared else copy.deepcopy(x_backbone)\n",
    "    return x_backbone, y_backbone\n",
    "\n",
    "\n",
    "def augmentation(args, x, device):\n",
    "    \"\"\"\n",
    "    Applies all the augmentations specified in the args\n",
    "    \"\"\"\n",
    "    # crop all jets to a fixed number of constituents (default=50)\n",
    "    x = crop_jets(x, args.nconstit)\n",
    "    x = rotate_jets(x, device)\n",
    "    y = x.clone()\n",
    "    if args.do_rotation:\n",
    "        y = rotate_jets(y, device)\n",
    "    if args.do_cf:\n",
    "        y = collinear_fill_jets(np.array(y.cpu()), device)\n",
    "        y = collinear_fill_jets(np.array(y.cpu()), device)\n",
    "    if args.do_ptd:\n",
    "        y = distort_jets(y, device, strength=args.ptst, pT_clip_min=args.ptcm)\n",
    "    if args.do_translation:\n",
    "        y = translate_jets(y, device, width=args.trsw)\n",
    "        x = translate_jets(x, device, width=args.trsw)\n",
    "    x = rescale_pts(x)  # [batch_size, 3, n_constit]\n",
    "    y = rescale_pts(y)  # [batch_size, 3, n_constit]\n",
    "    x = x.transpose(1, 2)  # [batch_size, 3, n_constit] -> [batch_size, n_constit, 3]\n",
    "    y = y.transpose(1, 2)  # [batch_size, 3, n_constit] -> [batch_size, n_constit, 3]\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d36c1eec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-21T23:49:07.677743Z",
     "start_time": "2023-08-21T23:49:07.673112Z"
    }
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "args.mask = False\n",
    "args.cmask = True\n",
    "args.epoch = 10\n",
    "args.batch_size = 256\n",
    "args.outdir = f\"{project_dir}/models/\"\n",
    "args.label = \"1-0.1-1e-4-100\"\n",
    "args.dataset_path = \"/ssl-jet-vol-v2/toptagging\"\n",
    "args.eval_path = f\"{project_dir}/models/model_performances/\"\n",
    "args.load_vicreg_path = f\"{project_dir}/models/trained_models/\"\n",
    "args.num_train_files = 1\n",
    "args.num_test_files = 1\n",
    "args.shared = False\n",
    "args.mlp = \"256-256-256\"\n",
    "args.transform_inputs = 32\n",
    "args.Do = 1000\n",
    "args.hidden = 128\n",
    "args.sim_coeff = 1.0\n",
    "args.std_coeff = 0.1\n",
    "args.cov_coeff = 1e-4\n",
    "args.return_embedding = False\n",
    "args.return_representation = True\n",
    "args.do_translation = True\n",
    "args.do_rotation = True\n",
    "args.do_cf = True\n",
    "args.do_ptd = True\n",
    "args.nconstit = 50\n",
    "args.ptst = 0.1\n",
    "args.ptcm = 0.1\n",
    "args.trsw = 1.0\n",
    "args.return_all_losses = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37d1070f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-21T23:54:28.132150Z",
     "start_time": "2023-08-21T23:53:18.620966Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device 0: NVIDIA A100 80GB PCIe MIG 1g.10gb\n",
      "--- loaded data file 0 from `train` directory\n",
      "--- loaded data file 0 from `test` directory\n",
      "--- loaded label file 0 from `train` directory\n",
      "--- loaded label file 0 from `test` directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "39: : 40it [00:28,  1.42it/s]                                                                                                          \n",
      "39: : 40it [00:27,  1.44it/s]                                                                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(rep layer 0) epoch: 0, loss: 46.482967\n",
      "(rep layer 0) epoch: 25, loss: 50.817123\n",
      "(rep layer 0) epoch: 50, loss: 50.811146\n",
      "(rep layer 0) epoch: 75, loss: 50.8231\n",
      "(rep layer 0) epoch: 100, loss: 50.811146\n",
      "(rep layer 0) epoch: 125, loss: 50.763313\n",
      "(rep layer 0) epoch: 150, loss: 50.867943\n",
      "(rep layer 0) epoch: 175, loss: 50.787228\n",
      "(rep layer 0) epoch: 200, loss: 50.77826\n",
      "(rep layer 0) epoch: 225, loss: 50.882893\n",
      "(rep layer 0) epoch: 250, loss: 50.775272\n",
      "(rep layer 0) epoch: 275, loss: 50.802177\n",
      "(rep layer 0) epoch: 300, loss: 50.80517\n",
      "(rep layer 0) epoch: 325, loss: 50.78125\n",
      "(rep layer 0) epoch: 350, loss: 50.748363\n",
      "(rep layer 0) epoch: 375, loss: 50.817123\n",
      "(rep layer 0) epoch: 400, loss: 50.882893\n",
      "(rep layer 0) epoch: 425, loss: 50.77826\n",
      "(rep layer 0) epoch: 450, loss: 50.79022\n",
      "(rep layer 0) epoch: 475, loss: 50.77826\n",
      "(rep layer 0) epoch: 500, loss: 50.799187\n",
      "(rep layer 0) epoch: 525, loss: 50.84403\n",
      "(rep layer 0) epoch: 550, loss: 50.817123\n",
      "(rep layer 0) epoch: 575, loss: 50.799187\n",
      "(rep layer 0) epoch: 600, loss: 50.82609\n",
      "(rep layer 0) epoch: 625, loss: 50.852997\n",
      "(rep layer 0) epoch: 650, loss: 50.733418\n",
      "(rep layer 0) epoch: 675, loss: 50.75733\n",
      "(rep layer 0) epoch: 700, loss: 50.796196\n",
      "(rep layer 0) epoch: 725, loss: 50.820114\n",
      "(rep layer 0) auc: 0.4343\n",
      "(rep layer 0) imtafe: 1.7\n"
     ]
    }
   ],
   "source": [
    "# define the global base device\n",
    "world_size = torch.cuda.device_count()\n",
    "if world_size:\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    for i in range(world_size):\n",
    "        print(f\"Device {i}: {torch.cuda.get_device_name(i)}\")\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    print(\"Device: CPU\")\n",
    "args.device = device\n",
    "\n",
    "args.augmentation = augmentation\n",
    "\n",
    "args.x_inputs = 3\n",
    "args.y_inputs = 3\n",
    "\n",
    "args.x_backbone, args.y_backbone = get_backbones(args)\n",
    "args.return_representation = True\n",
    "args.return_embedding = False\n",
    "# load the desired trained VICReg model\n",
    "model = VICReg(args).to(args.device)\n",
    "model.load_state_dict(torch.load(f\"{args.load_vicreg_path}/vicreg_{args.label}_best.pth\"))\n",
    "\n",
    "# load the training and testing dataset\n",
    "data_train = load_data(args.dataset_path, \"train\", n_files=args.num_train_files)\n",
    "data_test = load_data(args.dataset_path, \"test\", n_files=args.num_test_files)\n",
    "labels_train = load_labels(args.dataset_path, \"train\", n_files=args.num_train_files)\n",
    "labels_test = load_labels(args.dataset_path, \"test\", n_files=args.num_test_files)\n",
    "\n",
    "\n",
    "# TODO: delete when pasting back to LCT.py\n",
    "num_jets = 10000\n",
    "data_train = data_train[:num_jets]\n",
    "data_test = data_test[:num_jets]\n",
    "labels_train = labels_train[:num_jets]\n",
    "labels_test = labels_test[:num_jets]\n",
    "\n",
    "# concatenate the training and testing datasets\n",
    "data_train = torch.stack(data_train)\n",
    "data_test = torch.stack(data_test)\n",
    "labels_train = torch.tensor([t.item() for t in labels_train])\n",
    "labels_test = torch.tensor([t.item() for t in labels_test])\n",
    "\n",
    "n_train = data_train.shape[0]\n",
    "n_test = data_test.shape[0]\n",
    "\n",
    "batch_size = args.batch_size\n",
    "train_its = int(n_train / batch_size)\n",
    "test_its = int(n_test / batch_size)\n",
    "\n",
    "# obtain the representations from the trained VICReg model\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    train_loader = DataLoader(data_train, args.batch_size)\n",
    "    test_loader = DataLoader(data_test, args.batch_size)\n",
    "    tr_reps = []\n",
    "    pbar = tqdm.tqdm(train_loader, total=train_its)\n",
    "    for i, batch in enumerate(pbar):\n",
    "        batch = batch.to(args.device)\n",
    "        tr_reps.append(model(batch)[0].detach().cpu().numpy())\n",
    "        pbar.set_description(f\"{i}\")\n",
    "    tr_reps = np.concatenate(tr_reps)\n",
    "    te_reps = []\n",
    "    pbar = tqdm.tqdm(test_loader, total=test_its)\n",
    "    for i, batch in enumerate(pbar):\n",
    "        batch = batch.to(args.device)\n",
    "        te_reps.append(model(batch)[0].detach().cpu().numpy())\n",
    "        pbar.set_description(f\"{i}\")\n",
    "    te_reps = np.concatenate(te_reps)\n",
    "\n",
    "# perform the linear classifier test (LCT) on the representations\n",
    "i = 0\n",
    "linear_input_size = tr_reps.shape[1]\n",
    "linear_n_epochs = 750\n",
    "linear_learning_rate = 0.001\n",
    "linear_batch_size = 1024\n",
    "out_dat_f, out_lbs_f, losses_f = linear_classifier_test( linear_input_size, linear_batch_size, linear_n_epochs, linear_learning_rate, tr_reps, labels_train, te_reps, labels_test )\n",
    "auc, imtafe = get_perf_stats( out_lbs_f, out_dat_f )\n",
    "ep=0\n",
    "step_size = 25\n",
    "for lss in losses_f[::step_size]:\n",
    "    print( f\"(rep layer {i}) epoch: \" + str( ep ) + \", loss: \" + str( lss ), flush=True)\n",
    "    ep+=step_size\n",
    "print( f\"(rep layer {i}) auc: \"+str( round(auc, 4) ), flush=True)\n",
    "print( f\"(rep layer {i}) imtafe: \"+str( round(imtafe, 1) ), flush=True)\n",
    "np.save( args.eval_path+f\"{args.label}/linear_losses_{i}.npy\", losses_f )\n",
    "np.save( args.eval_path+f\"{args.label}/test_linear_cl_{i}.npy\", out_dat_f )\n",
    "np.save( args.eval_path+f\"{args.label}/test_linear_cl_labels_{i}.npy\", out_lbs_f )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4104e483",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-21T23:49:18.371930Z",
     "start_time": "2023-08-21T23:49:18.363675Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 3, 50])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "611d417f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-21T23:49:18.507308Z",
     "start_time": "2023-08-21T23:49:18.373470Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- loaded data file 0 from `train` directory\n"
     ]
    }
   ],
   "source": [
    "data_train = load_data(args.dataset_path, \"train\", n_files=args.num_train_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38f77b80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-21T23:49:18.512280Z",
     "start_time": "2023-08-21T23:49:18.509272Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 50])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9d19bdb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-21T23:49:18.578178Z",
     "start_time": "2023-08-21T23:49:18.513890Z"
    }
   },
   "outputs": [],
   "source": [
    "data_train_tensor = torch.stack(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7447a214",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-21T23:49:18.583014Z",
     "start_time": "2023-08-21T23:49:18.579956Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100001, 3, 50])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57cda184",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-21T23:49:18.588774Z",
     "start_time": "2023-08-21T23:49:18.584487Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([t.item() for t in labels_train]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d0c091f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-21T23:55:49.918477Z",
     "start_time": "2023-08-21T23:55:49.914083Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acf87ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
