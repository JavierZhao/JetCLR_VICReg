# generated by ChatGPT
import torch
import torch.nn.functional as F
from torch_geometric.nn import GATConv, global_mean_pool


class GATTransformer(torch.nn.Module):
    def __init__(
        self,
        input_dim=7,
        model_dim=1000,
        output_dim=1000,
        n_heads=4,
        dim_feedforward=1000,
        n_layers=4,
        learning_rate=0.00005,
        n_head_layers=2,
        head_norm=False,
        dropout=0.1,
        opt="adam",
    ):
        super().__init__()
        self.model_dim = model_dim
        self.output_dim = output_dim
        self.n_layers = n_layers
        self.learning_rate = learning_rate
        self.n_head_layers = n_head_layers
        self.head_norm = head_norm
        self.dropout = dropout

        self.embedding = torch.nn.Linear(input_dim, model_dim)
        self.head_layers = torch.nn.ModuleList()

        if head_norm:
            self.norm_layers = torch.nn.ModuleList([torch.nn.LayerNorm(model_dim)])

        for _ in range(n_layers):
            self.head_layers.append(
                GATConv(model_dim, model_dim // n_heads, heads=n_heads, dropout=dropout)
            )

        for i in range(n_head_layers - 1):
            if head_norm:
                self.norm_layers.append(torch.nn.LayerNorm(output_dim))
            self.head_layers.append(torch.nn.Linear(output_dim, output_dim))

        self.fc = torch.nn.Linear(model_dim, output_dim)

        if opt == "adam":
            self.optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)
        elif opt in ["sgdca", "sgdslr", "sgd"]:
            self.optimizer = torch.optim.SGD(
                self.parameters(), lr=learning_rate, momentum=0.9
            )

    def forward(self, data):
        x, edge_index = data.x, data.edge_index

        x = self.embedding(x)

        for layer in self.head_layers:
            x = F.relu(layer(x, edge_index))
            x = F.dropout(x, p=self.dropout, training=self.training)

        x = global_mean_pool(x, data.batch)  # Pooling
        x = self.fc(x)

        return x

    def forward_batchwise(self, data, batch_size):
        with torch.no_grad():
            out = []
            data_list = data.to_data_list()
            idx_list = torch.split(torch.arange(len(data_list)), batch_size)

            for idx in idx_list:
                batch_data = [data_list[i] for i in idx]
                batch_data = torch_geometric.data.Batch.from_data_list(batch_data)
                output = self(batch_data).detach().cpu()
                out.append(output)

            out = torch.cat(out, dim=0)

        return out
