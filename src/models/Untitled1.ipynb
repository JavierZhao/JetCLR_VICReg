{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e76cba50",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 23\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeatures\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mperf_eval\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_perf_stats, linear_classifier_test\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# if torch.cuda.is_available():\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#     import setGPU  # noqa: F401\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m project_dir \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;18;43m__file__\u001b[39;49m)\u001b[38;5;241m.\u001b[39mresolve()\u001b[38;5;241m.\u001b[39mparents[\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# definitions = f\"{project_dir}/src/data/definitions.yml\"\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# with open(definitions) as yaml_file:\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m#     defn = yaml.load(yaml_file, Loader=yaml.FullLoader)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# params = defn[\"features_2\"]\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# params_sv = defn[\"features_3\"]\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mVICReg\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import copy\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import tqdm\n",
    "import yaml\n",
    "from torch import nn\n",
    "\n",
    "from src.models.transformer import Transformer\n",
    "from src.models.jet_augs import *\n",
    "from src.features.perf_eval import get_perf_stats, linear_classifier_test\n",
    "\n",
    "# if torch.cuda.is_available():\n",
    "#     import setGPU  # noqa: F401\n",
    "\n",
    "project_dir = Path(__file__).resolve().parents[2]\n",
    "\n",
    "# definitions = f\"{project_dir}/src/data/definitions.yml\"\n",
    "# with open(definitions) as yaml_file:\n",
    "#     defn = yaml.load(yaml_file, Loader=yaml.FullLoader)\n",
    "\n",
    "# N = defn[\"nobj_2\"]  # number of charged particles\n",
    "# N_sv = defn[\"nobj_3\"]  # number of SVs\n",
    "# n_targets = len(defn[\"reduced_labels\"])  # number of classes\n",
    "# params = defn[\"features_2\"]\n",
    "# params_sv = defn[\"features_3\"]\n",
    "\n",
    "\n",
    "class VICReg(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "        self.args = args\n",
    "        self.num_features = int(\n",
    "            args.mlp.split(\"-\")[-1]\n",
    "        )  # size of the last layer of the MLP projector\n",
    "        self.x_transform = nn.Sequential(\n",
    "            nn.BatchNorm1d(args.x_inputs),\n",
    "            nn.Linear(args.x_inputs, args.transform_inputs),\n",
    "            nn.BatchNorm1d(args.transform_inputs),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.y_transform = nn.Sequential(\n",
    "            nn.BatchNorm1d(args.y_inputs),\n",
    "            nn.Linear(args.y_inputs, args.transform_inputs),\n",
    "            nn.BatchNorm1d(args.transform_inputs),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.augmentation = args.augmentation\n",
    "        self.x_backbone = args.x_backbone\n",
    "        self.y_backbone = args.y_backbone\n",
    "        self.N_x = self.x_backbone.input_dim\n",
    "        self.N_y = self.y_backbone.input_dim\n",
    "        self.embedding = args.feature_dim\n",
    "        self.return_embedding = args.return_embedding\n",
    "        # self.return_representation = args.return_representation\n",
    "        self.x_projector = Projector(args.mlp, self.embedding)\n",
    "        self.y_projector = (\n",
    "            self.x_projector if args.shared else copy.deepcopy(self.x_projector)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, return_rep=False):\n",
    "        \"\"\"\n",
    "        x -> x_aug -> (x_xform) -> x_rep -> x_emb\n",
    "        y -> y_aug -> (y_xform) -> y_rep -> y_emb\n",
    "        _aug: augmented\n",
    "        _xform: transformed by linear layer (skipped because it destroys the zero padding)\n",
    "        _rep: backbone representation\n",
    "        _emb: projected embedding\n",
    "        \"\"\"\n",
    "        if return_rep:\n",
    "            # Don't do augmentation, just return the backbone representation\n",
    "            y = x.clone()\n",
    "            x_aug = x.transpose(\n",
    "                1, 2\n",
    "            )  # [batch_size, 3, n_constit] -> [batch_size, n_constit, 3]\n",
    "            y_aug = y.transpose(\n",
    "                1, 2\n",
    "            )  # [batch_size, 3, n_constit] -> [batch_size, n_constit, 3]\n",
    "        else:\n",
    "            x_aug, y_aug = self.augmentation(\n",
    "                self.args, x, self.args.device\n",
    "            )  # [batch_size, n_constit, 3]\n",
    "        #         print(f\"x_aug contains nan: {contains_nan(x_aug)}\")\n",
    "        #         print(f\"y_aug contains nan: {contains_nan(y_aug)}\")\n",
    "\n",
    "        # x_xform = self.x_transform.to(torch.double)(\n",
    "        #     x_aug.x.double()\n",
    "        # )  # [batch_size, n_constit, transform_inputs]?\n",
    "        # y_xform = self.y_transform.to(torch.double)(\n",
    "        #     y_aug.x.double()\n",
    "        # )  # [batch_size, n_constit, transform_inputs]?\n",
    "\n",
    "        x_rep = self.x_backbone(\n",
    "            x_aug, use_mask=self.args.mask, use_continuous_mask=self.args.cmask\n",
    "        )  # [batch_size, output_dim]\n",
    "        y_rep = self.y_backbone(\n",
    "            y_aug, use_mask=self.args.mask, use_continuous_mask=self.args.cmask\n",
    "        )  # [batch_size, output_dim]\n",
    "        #         print(f\"x_rep contains nan: {contains_nan(x_rep)}\")\n",
    "        #         print(f\"y_rep contains nan: {contains_nan(y_rep)}\")\n",
    "        if return_rep:\n",
    "            return x_rep, y_rep\n",
    "\n",
    "        x_emb = self.x_projector(x_rep)  # [batch_size, embedding_size]\n",
    "        y_emb = self.y_projector(y_rep)  # [batch_size, embedding_size]\n",
    "        #         print(f\"x_emb contains nan: {contains_nan(x_emb)}\")\n",
    "        #         print(f\"y_emb contains nan: {contains_nan(y_emb)}\")\n",
    "        if self.return_embedding:\n",
    "            return x_emb, y_emb\n",
    "        x = x_emb\n",
    "        y = y_emb\n",
    "        repr_loss = F.mse_loss(x, y)\n",
    "\n",
    "        x = x - x.mean(dim=0)\n",
    "        y = y - y.mean(dim=0)\n",
    "\n",
    "        std_x = torch.sqrt(x.var(dim=0) + 0.0001)\n",
    "        std_y = torch.sqrt(y.var(dim=0) + 0.0001)\n",
    "        std_loss = torch.mean(F.relu(1 - std_x)) / 2 + torch.mean(F.relu(1 - std_y)) / 2\n",
    "\n",
    "        cov_x = (x.T @ x) / (self.args.batch_size - 1)\n",
    "        cov_y = (y.T @ y) / (self.args.batch_size - 1)\n",
    "        cov_loss = off_diagonal(cov_x).pow_(2).sum().div(\n",
    "            self.num_features\n",
    "        ) + off_diagonal(cov_y).pow_(2).sum().div(self.num_features)\n",
    "\n",
    "        loss = (\n",
    "            self.args.sim_coeff * repr_loss\n",
    "            + self.args.std_coeff * std_loss\n",
    "            + self.args.cov_coeff * cov_loss\n",
    "        )\n",
    "        if args.return_all_losses:\n",
    "            return loss, repr_loss, std_loss, cov_loss\n",
    "        else:\n",
    "            return loss\n",
    "\n",
    "\n",
    "def Projector(mlp, embedding):\n",
    "    mlp_spec = f\"{embedding}-{mlp}\"\n",
    "    layers = []\n",
    "    f = list(map(int, mlp_spec.split(\"-\")))\n",
    "    for i in range(len(f) - 2):\n",
    "        layers.append(nn.Linear(f[i], f[i + 1]))\n",
    "        layers.append(nn.BatchNorm1d(f[i + 1]))\n",
    "        layers.append(nn.ReLU())\n",
    "    layers.append(nn.Linear(f[-2], f[-1], bias=False))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "def off_diagonal(x):\n",
    "    n, m = x.shape\n",
    "    assert n == m\n",
    "    return x.flatten()[:-1].view(n - 1, n + 1)[:, 1:].flatten()\n",
    "\n",
    "\n",
    "def get_backbones(args):\n",
    "    x_backbone = Transformer(input_dim=args.x_inputs, output_dim=args.feature_dim, model_dim=args.model_dim, dim_feedforward=args.model_dim)\n",
    "    y_backbone = x_backbone if args.shared else copy.deepcopy(x_backbone)\n",
    "    return x_backbone, y_backbone\n",
    "\n",
    "\n",
    "def augmentation(args, x, device):\n",
    "    \"\"\"\n",
    "    Applies all the augmentations specified in the args\n",
    "    \"\"\"\n",
    "    # crop all jets to a fixed number of constituents (default=50)\n",
    "    x = crop_jets(x, args.nconstit)\n",
    "    x = rotate_jets(x, device)\n",
    "    y = x.clone()\n",
    "    if args.do_rotation:\n",
    "        y = rotate_jets(y, device)\n",
    "    if args.do_cf:\n",
    "        y = collinear_fill_jets(np.array(y.cpu()), device)\n",
    "        y = collinear_fill_jets(np.array(y.cpu()), device)\n",
    "    if args.do_ptd:\n",
    "        y = distort_jets(y, device, strength=args.ptst, pT_clip_min=args.ptcm)\n",
    "    if args.do_translation:\n",
    "        y = translate_jets(y, device, width=args.trsw)\n",
    "        x = translate_jets(x, device, width=args.trsw)\n",
    "    x = rescale_pts(x)  # [batch_size, 3, n_constit]\n",
    "    y = rescale_pts(y)  # [batch_size, 3, n_constit]\n",
    "    x = x.transpose(1, 2)  # [batch_size, 3, n_constit] -> [batch_size, n_constit, 3]\n",
    "    y = y.transpose(1, 2)  # [batch_size, 3, n_constit] -> [batch_size, n_constit, 3]\n",
    "    return x, y\n",
    "\n",
    "\n",
    "# load the datafiles\n",
    "def load_data(dataset_path, flag, n_files=-1):\n",
    "    data_files = glob.glob(f\"{dataset_path}/{flag}/processed/3_features/*\")\n",
    "\n",
    "    data = []\n",
    "    for i, file in enumerate(data_files):\n",
    "        data += torch.load(f\"{dataset_path}/{flag}/processed/3_features/data_{i}.pt\")\n",
    "        print(f\"--- loaded file {i} from `{flag}` directory\")\n",
    "        if n_files != -1 and i == n_files - 1:\n",
    "            break\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_labels(dataset_path, flag, n_files=-1):\n",
    "    data_files = glob.glob(f\"{dataset_path}/{flag}/processed/3_features/*\")\n",
    "\n",
    "    data = []\n",
    "    for i, file in enumerate(data_files):\n",
    "        data += torch.load(f\"{dataset_path}/{flag}/processed/3_features/labels_{i}.pt\")\n",
    "        print(f\"--- loaded label file {i} from `{flag}` directory\")\n",
    "        if n_files != -1 and i == n_files - 1:\n",
    "            break\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    # define the global base device\n",
    "    world_size = torch.cuda.device_count()\n",
    "    if world_size:\n",
    "        device = torch.device(\"cuda:0\")\n",
    "        for i in range(world_size):\n",
    "            print(f\"Device {i}: {torch.cuda.get_device_name(i)}\")\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "        print(\"Device: CPU\")\n",
    "    args.device = device\n",
    "\n",
    "    n_epochs = args.epoch\n",
    "    batch_size = args.batch_size\n",
    "    outdir = args.outdir\n",
    "    label = args.label\n",
    "\n",
    "    model_loc = f\"{outdir}/trained_models/\"\n",
    "    model_perf_loc = f\"{outdir}/model_performances/{label}\"\n",
    "    model_dict_loc = f\"{outdir}/model_dicts/\"\n",
    "    os.system(\n",
    "        f\"mkdir -p {model_loc} {model_perf_loc} {model_dict_loc}\"\n",
    "    )  # -p: create parent dirs if needed, exist_ok\n",
    "\n",
    "    # prepare data\n",
    "    data_train = load_data(args.dataset_path, \"train\", n_files=args.num_train_files)\n",
    "    data_valid = load_data(args.dataset_path, \"val\", n_files=args.num_val_files)\n",
    "    data_test = load_data(args.dataset_path, \"test\", n_files=1)\n",
    "\n",
    "    labels_train = load_labels(args.dataset_path, \"train\", n_files=args.num_train_files)\n",
    "    labels_test = load_labels(args.dataset_path, \"test\", n_files=1)\n",
    "\n",
    "    # only take the first 10k jets for LCT\n",
    "    labels_train = labels_train[:10000]\n",
    "    labels_test = labels_test[:10000]\n",
    "\n",
    "    labels_train = torch.tensor([t.item() for t in labels_train])\n",
    "    labels_test = torch.tensor([t.item() for t in labels_test])\n",
    "\n",
    "    n_train = len(data_train)\n",
    "    n_val = len(data_valid)\n",
    "\n",
    "    args.augmentation = augmentation\n",
    "\n",
    "    args.x_inputs = 3\n",
    "    args.y_inputs = 3\n",
    "\n",
    "    args.x_backbone, args.y_backbone = get_backbones(args)\n",
    "    model = VICReg(args).to(args.device)\n",
    "    print(model)\n",
    "\n",
    "    train_its = int(n_train / batch_size)\n",
    "    val_its = int(n_val / batch_size)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "    loss_val_epochs = []  # loss recorded for each epoch\n",
    "    repr_loss_val_epochs, std_loss_val_epochs, cov_loss_val_epochs = [], [], []\n",
    "    # invariance, variance, covariance loss recorded for each epoch\n",
    "    loss_val_batches = []  # loss recorded for each batch\n",
    "    loss_train_epochs = []  # loss recorded for each epoch\n",
    "    repr_loss_train_epochs, std_loss_train_epochs, cov_loss_train_epochs = [], [], []\n",
    "    # invariance, variance, covariance loss recorded for each epoch\n",
    "    loss_train_batches = []  # loss recorded for each batch\n",
    "    l_val_best = 999999\n",
    "    for m in range(n_epochs):\n",
    "        print(f\"Epoch {m}\\n\")\n",
    "        loss_train_epoch = []  # loss recorded for each batch in this epoch\n",
    "        repr_loss_train_epoch, std_loss_train_epoch, cov_loss_train_epoch = [], [], []\n",
    "        # invariance, variance, covariance loss recorded for each batch in this epoch\n",
    "        loss_val_epoch = []  # loss recorded for each batch in this epoch\n",
    "        repr_loss_val_epoch, std_loss_val_epoch, cov_loss_val_epoch = [], [], []\n",
    "        # invariance, variance, covariance loss recorded for each batch in this epoch\n",
    "\n",
    "        train_loader = DataLoader(data_train, batch_size)\n",
    "        model.train()\n",
    "        pbar_t = tqdm.tqdm(train_loader, total=train_its)\n",
    "        for _, batch in enumerate(pbar_t):\n",
    "            batch = batch.to(args.device)\n",
    "            # batch = convert_x(batch, args.device)\n",
    "            optimizer.zero_grad()\n",
    "            if args.return_all_losses:\n",
    "                loss, repr_loss, std_loss, cov_loss = model.forward(batch)\n",
    "                #             print(loss, repr_loss, std_loss, cov_loss)\n",
    "                repr_loss_train_epoch.append(repr_loss.detach().cpu().item())\n",
    "                std_loss_train_epoch.append(std_loss.detach().cpu().item())\n",
    "                cov_loss_train_epoch.append(cov_loss.detach().cpu().item())\n",
    "            else:\n",
    "                loss = model.forward(batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss = loss.detach().cpu().item()\n",
    "            loss_train_batches.append(loss)\n",
    "            loss_train_epoch.append(loss)\n",
    "            pbar_t.set_description(f\"Training loss: {loss:.4f}\")\n",
    "        #             print(f\"Training loss: {loss:.4f}\")\n",
    "        l_train = np.mean(np.array(loss_train_epoch))\n",
    "        print(f\"Training loss: {l_train:.4f}\")\n",
    "        model.eval()\n",
    "        valid_loader = DataLoader(data_valid, batch_size)\n",
    "        pbar_v = tqdm.tqdm(valid_loader, total=val_its)\n",
    "        #     for _, batch in tqdm.tqdm(enumerate(valid_loader)):\n",
    "        with torch.no_grad():\n",
    "            for _, batch in enumerate(pbar_v):\n",
    "                batch = batch.to(args.device)\n",
    "                # batch = convert_x(batch, args.device)  # [batch_size, 3, n_constit]\n",
    "                if args.return_all_losses:\n",
    "                    loss, repr_loss, std_loss, cov_loss = model.forward(batch)\n",
    "                    repr_loss_val_epoch.append(repr_loss.detach().cpu().item())\n",
    "                    std_loss_val_epoch.append(std_loss.detach().cpu().item())\n",
    "                    cov_loss_val_epoch.append(cov_loss.detach().cpu().item())\n",
    "                    loss = loss.detach().cpu().item()\n",
    "                else:\n",
    "                    loss = model.forward(batch).cpu().item()\n",
    "                loss_val_batches.append(loss)\n",
    "                loss_val_epoch.append(loss)\n",
    "                pbar_v.set_description(f\"Validation loss: {loss:.4f}\")\n",
    "        #             print(f\"Validation loss: {loss:.4f}\")\n",
    "        l_val = np.mean(np.array(loss_val_epoch))\n",
    "        print(f\"Validation loss: {l_val:.4f}\")\n",
    "        loss_val_epochs.append(l_val)\n",
    "        loss_train_epochs.append(l_train)\n",
    "\n",
    "        if args.return_all_losses:\n",
    "            repr_l_val = np.mean(np.array(repr_loss_val_epoch))\n",
    "            repr_l_train = np.mean(np.array(repr_loss_train_epoch))\n",
    "            std_l_val = np.mean(np.array(std_loss_val_epoch))\n",
    "            std_l_train = np.mean(np.array(std_loss_train_epoch))\n",
    "            cov_l_val = np.mean(np.array(cov_loss_val_epoch))\n",
    "            cov_l_train = np.mean(np.array(cov_loss_train_epoch))\n",
    "\n",
    "            repr_loss_val_epochs.append(repr_l_val)\n",
    "            std_loss_val_epochs.append(std_l_val)\n",
    "            cov_loss_val_epochs.append(cov_l_val)\n",
    "\n",
    "            repr_loss_train_epochs.append(repr_l_train)\n",
    "            std_loss_train_epochs.append(std_l_train)\n",
    "            cov_loss_train_epochs.append(cov_l_train)\n",
    "        # save the model\n",
    "        if l_val < l_val_best:\n",
    "            print(\"New best model\")\n",
    "            l_val_best = l_val\n",
    "            torch.save(model.state_dict(), f\"{model_loc}/vicreg_{label}_best.pth\")\n",
    "        torch.save(model.state_dict(), f\"{model_loc}/vicreg_{label}_last.pth\")\n",
    "        # save model performance\n",
    "        np.save(\n",
    "        f\"{model_perf_loc}/vicreg_{label}_loss_train_epochs.npy\",\n",
    "        np.array(loss_train_epochs),\n",
    "        )\n",
    "        np.save(\n",
    "            f\"{model_perf_loc}/vicreg_{label}_loss_train_batches.npy\",\n",
    "            np.array(loss_train_batches),\n",
    "        )\n",
    "        np.save(\n",
    "            f\"{model_perf_loc}/vicreg_{label}_loss_val_epochs.npy\",\n",
    "            np.array(loss_val_epochs),\n",
    "        )\n",
    "        np.save(\n",
    "            f\"{model_perf_loc}/vicreg_{label}_loss_val_batches.npy\",\n",
    "            np.array(loss_val_batches),\n",
    "        )\n",
    "        if args.return_all_losses:\n",
    "            np.save(\n",
    "                f\"{model_perf_loc}/vicreg_{label}_repr_loss_train_epochs.npy\",\n",
    "                np.array(repr_loss_train_epochs),\n",
    "            )\n",
    "            np.save(\n",
    "                f\"{model_perf_loc}/vicreg_{label}_std_loss_train_epochs.npy\",\n",
    "                np.array(std_loss_train_epochs),\n",
    "            )\n",
    "            np.save(\n",
    "                f\"{model_perf_loc}/vicreg_{label}_cov_loss_train_epochs.npy\",\n",
    "                np.array(cov_loss_train_epochs),\n",
    "            )\n",
    "            np.save(\n",
    "                f\"{model_perf_loc}/vicreg_{label}_repr_loss_val_epochs.npy\",\n",
    "                np.array(repr_loss_val_epochs),\n",
    "            )\n",
    "            np.save(\n",
    "                f\"{model_perf_loc}/vicreg_{label}_std_loss_val_epochs.npy\",\n",
    "                np.array(std_loss_val_epochs),\n",
    "            )\n",
    "            np.save(\n",
    "                f\"{model_perf_loc}/vicreg_{label}_cov_loss_val_epochs.npy\",\n",
    "                np.array(cov_loss_val_epochs),\n",
    "            )\n",
    "        if m % 10 == 0:\n",
    "            # do a short LCT\n",
    "            model.eval()\n",
    "            print(\"Doing LCT\")\n",
    "            with torch.no_grad():\n",
    "                train_loader = DataLoader(data_train[:10000], args.batch_size)\n",
    "                test_loader = DataLoader(data_test[:10000], args.batch_size)\n",
    "                tr_reps = []\n",
    "                batch_size = args.batch_size\n",
    "                # train_its = int(10000 / batch_size)\n",
    "                # test_its = int(10000 / batch_size)\n",
    "                # pbar = tqdm.tqdm(train_loader, total=train_its)\n",
    "                for i, batch in enumerate(train_loader):\n",
    "                    batch = batch.to(args.device)\n",
    "                    tr_reps.append(\n",
    "                        model(batch, return_rep=True)[0].detach().cpu().numpy()\n",
    "                    )\n",
    "                    # pbar.set_description(f\"{i}\")\n",
    "                tr_reps = np.concatenate(tr_reps)\n",
    "                te_reps = []\n",
    "                # pbar = tqdm.tqdm(test_loader, total=test_its)\n",
    "                for i, batch in enumerate(test_loader):\n",
    "                    batch = batch.to(args.device)\n",
    "                    te_reps.append(\n",
    "                        model(batch, return_rep=True)[0].detach().cpu().numpy()\n",
    "                    )\n",
    "                    # pbar.set_description(f\"{i}\")\n",
    "                te_reps = np.concatenate(te_reps)\n",
    "\n",
    "            # perform the linear classifier test (LCT) on the representations\n",
    "            i = 0\n",
    "            linear_input_size = tr_reps.shape[1]\n",
    "            linear_n_epochs = 750\n",
    "            linear_learning_rate = 0.001\n",
    "            linear_batch_size = 1000\n",
    "            out_dat_f, out_lbs_f, losses_f = linear_classifier_test(\n",
    "                linear_input_size,\n",
    "                linear_batch_size,\n",
    "                linear_n_epochs,\n",
    "                linear_learning_rate,\n",
    "                tr_reps,\n",
    "                labels_train,\n",
    "                te_reps,\n",
    "                labels_test,\n",
    "            )\n",
    "            auc, imtafe = get_perf_stats(out_lbs_f, out_dat_f)\n",
    "            ep = 0\n",
    "            step_size = 100\n",
    "            for lss in losses_f[::step_size]:\n",
    "                print(\n",
    "                    f\"(rep layer {i}) epoch: \" + str(ep) + \", loss: \" + str(lss),\n",
    "                    flush=True,\n",
    "                )\n",
    "                ep += step_size\n",
    "            print(f\"(rep layer {i}) auc: \" + str(round(auc, 4)), flush=True)\n",
    "            print(f\"(rep layer {i}) imtafe: \" + str(round(imtafe, 1)), flush=True)\n",
    "    #  training complete\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\"This is executed when run from the command line\"\"\"\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--dataset-path\",\n",
    "        type=str,\n",
    "        action=\"store\",\n",
    "        default=f\"{project_dir}/data/processed/train/\",\n",
    "        help=\"Input directory with the dataset\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--num-train-files\",\n",
    "        type=int,\n",
    "        default=12,\n",
    "        help=\"Number of files to use for training\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--num-val-files\",\n",
    "        type=int,\n",
    "        default=4,\n",
    "        help=\"Number of files to use for validation\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--outdir\",\n",
    "        type=str,\n",
    "        action=\"store\",\n",
    "        dest=\"outdir\",\n",
    "        default=f\"{project_dir}/models/\",\n",
    "        help=\"Output directory\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--transform-inputs\",\n",
    "        type=int,\n",
    "        action=\"store\",\n",
    "        dest=\"transform_inputs\",\n",
    "        default=32,\n",
    "        help=\"transform_inputs\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--feature-dim\",\n",
    "        type=int,\n",
    "        action=\"store\",\n",
    "        dest=\"feature_dim\",\n",
    "        default=1000,\n",
    "        help=\"dimension of learned feature space\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--model-dim\",\n",
    "        type=int,\n",
    "        action=\"store\",\n",
    "        dest=\"model_dim\",\n",
    "        default=1000,\n",
    "        help=\"dimension of the transformer-encoder\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--shared\",\n",
    "        type=bool,\n",
    "        action=\"store\",\n",
    "        default=True,\n",
    "        help=\"share parameters of backbone\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--mask\",\n",
    "        type=bool,\n",
    "        action=\"store\",\n",
    "        default=False,\n",
    "        help=\"use mask in transformer\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--cmask\",\n",
    "        type=bool,\n",
    "        action=\"store\",\n",
    "        default=True,\n",
    "        help=\"use continuous mask in transformer\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--epoch\", type=int, action=\"store\", dest=\"epoch\", default=200, help=\"Epochs\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--label\",\n",
    "        type=str,\n",
    "        action=\"store\",\n",
    "        dest=\"label\",\n",
    "        default=\"new\",\n",
    "        help=\"a label for the model\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--batch-size\",\n",
    "        type=int,\n",
    "        action=\"store\",\n",
    "        dest=\"batch_size\",\n",
    "        default=1024,\n",
    "        help=\"batch_size\",\n",
    "    )\n",
    "    # parser.add_argument(\n",
    "    #     \"--device\",\n",
    "    #     action=\"store\",\n",
    "    #     dest=\"device\",\n",
    "    #     default=\"cuda\",\n",
    "    #     help=\"device to train gnn; follow pytorch convention\",\n",
    "    # )\n",
    "    parser.add_argument(\n",
    "        \"--mlp\",\n",
    "        default=\"256-256-256\",\n",
    "        help=\"Size and number of layers of the MLP expander head\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--sim-coeff\",\n",
    "        type=float,\n",
    "        default=25.0,\n",
    "        help=\"Invariance regularization loss coefficient\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--std-coeff\",\n",
    "        type=float,\n",
    "        default=25.0,\n",
    "        help=\"Variance regularization loss coefficient\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--cov-coeff\",\n",
    "        type=float,\n",
    "        default=1.0,\n",
    "        help=\"Covariance regularization loss coefficient\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--return-embedding\",\n",
    "        type=bool,\n",
    "        action=\"store\",\n",
    "        dest=\"return_embedding\",\n",
    "        default=False,\n",
    "        help=\"return_embedding\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--return-representation\",\n",
    "        type=bool,\n",
    "        action=\"store\",\n",
    "        dest=\"return_representation\",\n",
    "        default=False,\n",
    "        help=\"return_representation\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--do-translation\",\n",
    "        type=bool,\n",
    "        action=\"store\",\n",
    "        dest=\"do_translation\",\n",
    "        default=True,\n",
    "        help=\"do_translation\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--do-rotation\",\n",
    "        type=bool,\n",
    "        action=\"store\",\n",
    "        dest=\"do_rotation\",\n",
    "        default=True,\n",
    "        help=\"do_rotation\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--do-cf\",\n",
    "        type=bool,\n",
    "        action=\"store\",\n",
    "        dest=\"do_cf\",\n",
    "        default=True,\n",
    "        help=\"do collinear splitting\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--do-ptd\",\n",
    "        type=bool,\n",
    "        action=\"store\",\n",
    "        dest=\"do_ptd\",\n",
    "        default=True,\n",
    "        help=\"do soft splitting (distort_jets)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--nconstit\",\n",
    "        type=int,\n",
    "        action=\"store\",\n",
    "        dest=\"nconstit\",\n",
    "        default=50,\n",
    "        help=\"number of constituents per jet\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--ptst\",\n",
    "        type=float,\n",
    "        action=\"store\",\n",
    "        dest=\"ptst\",\n",
    "        default=0.1,\n",
    "        help=\"strength param in distort_jets\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--ptcm\",\n",
    "        type=float,\n",
    "        action=\"store\",\n",
    "        dest=\"ptcm\",\n",
    "        default=0.1,\n",
    "        help=\"pT_clip_min param in distort_jets\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--trsw\",\n",
    "        type=float,\n",
    "        action=\"store\",\n",
    "        dest=\"trsw\",\n",
    "        default=1.0,\n",
    "        help=\"width param in translate_jets\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--return-all-losses\",\n",
    "        type=bool,\n",
    "        action=\"store\",\n",
    "        dest=\"return_all_losses\",\n",
    "        default=True,\n",
    "        help=\"return the three terms in the loss function as well\",\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    main(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165d20e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
