# generated by ChatGPT
import torch
import torch.nn.functional as F
from torch_geometric.nn import GATConv, global_mean_pool


class GATTransformer(torch.nn.Module):
    def __init__(
        self,
        input_dim=7,
        model_dim=1000,
        output_dim=1000,
        n_heads=4,
        dim_feedforward=1000,
        n_layers=4,
        learning_rate=0.00005,
        n_head_layers=2,
        head_norm=False,
        dropout=0.1,
        opt="adam",
    ):
        super().__init__()
        self.model_dim = model_dim
        self.output_dim = output_dim
        self.n_layers = n_layers
        self.learning_rate = learning_rate
        self.n_head_layers = n_head_layers
        self.head_norm = head_norm
        self.dropout = dropout

        self.embedding = torch.nn.Linear(input_dim, model_dim)
        self.head_layers = torch.nn.ModuleList()

        if head_norm:
            self.norm_layers = torch.nn.ModuleList([torch.nn.LayerNorm(model_dim)])

        for _ in range(n_layers):
            self.head_layers.append(
                GATConv(model_dim, model_dim // n_heads, heads=n_heads, dropout=dropout)
            )

        for i in range(n_head_layers - 1):
            if head_norm:
                self.norm_layers.append(torch.nn.LayerNorm(output_dim))
            self.head_layers.append(torch.nn.Linear(output_dim, output_dim))

        self.fc = torch.nn.Linear(model_dim, output_dim)

        if opt == "adam":
            self.optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)
        elif opt in ["sgdca", "sgdslr", "sgd"]:
            self.optimizer = torch.optim.SGD(
                self.parameters(), lr=learning_rate, momentum=0.9
            )

    def forward(self, view1, view2):
        x_1, edge_index_1 = view1.x, view1.edge_index
        x_2, edge_index_2 = view2.x, view2.edge_index

        x_1 = self.embedding(x_1)
        x_2 = self.embedding(x_2)

        for layer in self.head_layers:
            x_1 = F.relu(layer(x_1, edge_index_1))
            x_1 = F.dropout(x_1, p=self.dropout, training=self.training)
            x_2 = F.relu(layer(x_2, edge_index_2))
            x_2 = F.dropout(x_2, p=self.dropout, training=self.training)

        x_1 = global_mean_pool(x_1, x_1.batch)  # Pooling
        x_1 = self.fc(x_1)
        x_2 = global_mean_pool(x_2, x_2.batch)  # Pooling
        x_2 = self.fc(x_2)

        return x_1, x_2
